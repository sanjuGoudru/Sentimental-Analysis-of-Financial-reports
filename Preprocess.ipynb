{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd, re\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('cik_list.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  \n",
       "0  edgar/data/3662/0000950170-98-000413.txt  \n",
       "1  edgar/data/3662/0000950170-98-001001.txt  \n",
       "2  edgar/data/3662/0000950172-98-000783.txt  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CIK', 'CONAME', 'FYRMO', 'FDATE', 'FORM', 'SECFNAME'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_name(secfname):\n",
    "    splitted = secfname.split(sep=\"/\")\n",
    "    name = \"+\".join(splitted)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all non-alphanumeric characters except newline and space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('./input_dir/edgar+data+11860+0000011860-00-000019.txt','r', encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "    print(len('\\n'.join(lines)))\n",
    "    for i in range(len(lines)):\n",
    "        lines[i] = re.sub(r'[^A-Za-z0-9\\n\\t ]+', ' ', lines[i])\n",
    "    print(len('\\n'.join(lines)))\n",
    "    for i in range(len(lines)):\n",
    "        lines[i] = re.sub(r'[^A-Za-z\\n\\t ]+', ' ', lines[i])\n",
    "    print(len('\\n'.join(lines)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def preprocess(secfname):\n",
    "    file_path = './input_dir/'+encode_name(secfname)\n",
    "    with open(file_path,'r', encoding=\"utf-8\") as file:\n",
    "        data = file.read()\n",
    "        ## Remove all non-aphabetic characters except newline character\n",
    "        for i in range(len(lines)):\n",
    "            lines[i] = re.sub(r'[^A-Za-z\\n ]+', ' ', lines[i])\n",
    "            lines[i] = re.sub(' +', ' ', lines[i])\n",
    "        ## Remove lines with length less than 3\n",
    "        lines = [x for x in lines if len(x)>=3]\n",
    "        \n",
    "    write_path = './input_dir/new/'+encode_name(secfname)\n",
    "    with open(write_path,'w', encoding=\"utf-8\") as w_file:\n",
    "        w_file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "147    None\n",
       "148    None\n",
       "149    None\n",
       "150    None\n",
       "151    None\n",
       "Name: SECFNAME, Length: 152, dtype: object"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SECFNAME'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./StopWords_Generic.txt' ,'r') as stop_words_file:\n",
    "    stopwords = stop_words_file.read()\n",
    "    stopwords = stopwords.lower().split(sep='\\n')\n",
    "\n",
    "def remove_stop_words(text):    \n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_data = [w for w in word_tokens if not w in stopwords]\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pos_words.txt','r') as pw_f:\n",
    "    pw=pw_f.read()\n",
    "    pw_list = pw.split('\\n')\n",
    "\n",
    "def get_positive_score(filtered_text_list):\n",
    "    pw_count = 0\n",
    "    for word in filtered_text_list:\n",
    "        if word in pw_list:\n",
    "            pw_count = pw_count + 1\n",
    "    return pw_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./neg_words.txt','r') as nw_f:\n",
    "    nw = nw_f.read()\n",
    "    nw_list = nw.split('\\n')\n",
    "\n",
    "def get_negative_score(filtered_text_list):\n",
    "    nw_count = 0\n",
    "    for word in filtered_text_list:\n",
    "        if word in nw_list:\n",
    "            nw_count = nw_count + 1\n",
    "    return nw_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity_score(pos_score, neg_score):\n",
    "    pol_score = (pos_score - neg_score) / ((pos_score + neg_score) + 0.000001)\n",
    "    return pol_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_sentence_length(sent_tokens,filtered_text_list):\n",
    "    sent_len,word_len = len(sent_tokens),len(filtered_text_list)\n",
    "    if sent_len !=0:\n",
    "        avg_sent_len = word_len/(1.0*sent_len)\n",
    "    else:\n",
    "        avg_sent_len = -1\n",
    "    return avg_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtained code from https://eayd.in/?p=232\n",
    "\n",
    "def sylco(word) :\n",
    "\n",
    "    word = word.lower()\n",
    "\n",
    "    # exception_add are words that need extra syllables\n",
    "    # exception_del are words that need less syllables\n",
    "\n",
    "    exception_add = ['serious','crucial']\n",
    "    exception_del = ['fortunately','unfortunately']\n",
    "\n",
    "    co_one = ['cool','coach','coat','coal','count','coin','coarse','coup','coif','cook','coign','coiffe','coof','court']\n",
    "    co_two = ['coapt','coed','coinci']\n",
    "\n",
    "    pre_one = ['preach']\n",
    "\n",
    "    syls = 0 #added syllable number\n",
    "    disc = 0 #discarded syllable number\n",
    "\n",
    "    #1) if letters < 3 : return 1\n",
    "    if len(word) <= 3 :\n",
    "        syls = 1\n",
    "        return syls\n",
    "\n",
    "    #2) if doesn't end with \"ted\" or \"tes\" or \"ses\" or \"ied\" or \"ies\", discard \"es\" and \"ed\" at the end.\n",
    "    # if it has only 1 vowel or 1 set of consecutive vowels, discard. (like \"speed\", \"fled\" etc.)\n",
    "\n",
    "    if word[-2:] == \"es\" or word[-2:] == \"ed\" :\n",
    "        doubleAndtripple_1 = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "        if doubleAndtripple_1 > 1 or len(re.findall(r'[eaoui][^eaoui]',word)) > 1 :\n",
    "            if word[-3:] == \"ted\" or word[-3:] == \"tes\" or word[-3:] == \"ses\" or word[-3:] == \"ied\" or word[-3:] == \"ies\" :\n",
    "                pass\n",
    "            else :\n",
    "                disc+=1\n",
    "\n",
    "    #3) discard trailing \"e\", except where ending is \"le\"  \n",
    "\n",
    "    le_except = ['whole','mobile','pole','male','female','hale','pale','tale','sale','aisle','whale','while']\n",
    "\n",
    "    if word[-1:] == \"e\" :\n",
    "        if word[-2:] == \"le\" and word not in le_except :\n",
    "            pass\n",
    "\n",
    "        else :\n",
    "            disc+=1\n",
    "\n",
    "    #4) check if consecutive vowels exists, triplets or pairs, count them as one.\n",
    "\n",
    "    doubleAndtripple = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "    tripple = len(re.findall(r'[eaoui][eaoui][eaoui]',word))\n",
    "    disc+=doubleAndtripple + tripple\n",
    "\n",
    "    #5) count remaining vowels in word.\n",
    "    numVowels = len(re.findall(r'[eaoui]',word))\n",
    "\n",
    "    #6) add one if starts with \"mc\"\n",
    "    if word[:2] == \"mc\" :\n",
    "        syls+=1\n",
    "\n",
    "    #7) add one if ends with \"y\" but is not surrouned by vowel\n",
    "    if word[-1:] == \"y\" and word[-2] not in \"aeoui\" :\n",
    "        syls +=1\n",
    "\n",
    "    #8) add one if \"y\" is surrounded by non-vowels and is not in the last word.\n",
    "\n",
    "    for i,j in enumerate(word) :\n",
    "        if j == \"y\" :\n",
    "            if (i != 0) and (i != len(word)-1) :\n",
    "                if word[i-1] not in \"aeoui\" and word[i+1] not in \"aeoui\" :\n",
    "                    syls+=1\n",
    "\n",
    "    #9) if starts with \"tri-\" or \"bi-\" and is followed by a vowel, add one.\n",
    "\n",
    "    if word[:3] == \"tri\" and word[3] in \"aeoui\" :\n",
    "        syls+=1\n",
    "\n",
    "    if word[:2] == \"bi\" and word[2] in \"aeoui\" :\n",
    "        syls+=1\n",
    "\n",
    "    #10) if ends with \"-ian\", should be counted as two syllables, except for \"-tian\" and \"-cian\"\n",
    "\n",
    "    if word[-3:] == \"ian\" : \n",
    "    #and (word[-4:] != \"cian\" or word[-4:] != \"tian\") :\n",
    "        if word[-4:] == \"cian\" or word[-4:] == \"tian\" :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #11) if starts with \"co-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "\n",
    "    if word[:2] == \"co\" and word[2] in 'eaoui' :\n",
    "\n",
    "        if word[:4] in co_two or word[:5] in co_two or word[:6] in co_two :\n",
    "            syls+=1\n",
    "        elif word[:4] in co_one or word[:5] in co_one or word[:6] in co_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #12) if starts with \"pre-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "\n",
    "    if word[:3] == \"pre\" and word[3] in 'eaoui' :\n",
    "        if word[:6] in pre_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #13) check for \"-n't\" and cross match with dictionary to add syllable.\n",
    "\n",
    "    negative = [\"doesn't\", \"isn't\", \"shouldn't\", \"couldn't\",\"wouldn't\"]\n",
    "\n",
    "    if word[-3:] == \"n't\" :\n",
    "        if word in negative :\n",
    "            syls+=1\n",
    "        else :\n",
    "            pass   \n",
    "\n",
    "    #14) Handling the exceptional words.\n",
    "\n",
    "    if word in exception_del :\n",
    "        disc+=1\n",
    "\n",
    "    if word in exception_add :\n",
    "        syls+=1     \n",
    "\n",
    "    # calculate the output\n",
    "    return numVowels - disc + syls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perc_complex_words(words):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if sylco(word)>=2:\n",
    "            count = count + 1\n",
    "    if len(words) == 0:\n",
    "        perc_complex_words = 0\n",
    "    else:\n",
    "        perc_complex_words = (100.0*count)/(1.0*len(words))\n",
    "    return count,perc_complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fog_index(avg_sent_length,perc_complex_words):\n",
    "    return 0.4 * (avg_sent_length + perc_complex_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertain_words = list(pd.read_excel('uncertainty_dictionary.xlsx')['Word'])\n",
    "uncertain_words = [item.lower() for item in uncertain_words]\n",
    "\n",
    "def get_uncertainity_score(words):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if word in uncertain_words:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "constrain_words = list(pd.read_excel('constraining_dictionary.xlsx')['Word'])\n",
    "constrain_words = [item.lower() for item in constrain_words]\n",
    "global_constrain_count,global_word_count = 0,0\n",
    "\n",
    "def get_constrain_score(words):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if word in constrain_words:\n",
    "            count += 1\n",
    "    #global_constrain_count += count\n",
    "    #global_word_count += len(words)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(secfname):\n",
    "    file_path = './input_dir/'+encode_name(secfname)\n",
    "    with open(file_path,'r', encoding=\"utf-8\") as file:\n",
    "        data = file.read()\n",
    "    soup = BS(data,'lxml')\n",
    "    ## Convert soup text to lowercase\n",
    "    data = soup.text.lower()\n",
    "    ## Remove all non-alpha characters except newline and full-stop(end of sentence character)\n",
    "    data = re.sub(r'[^A-Za-z\\n\\. ]+', ' ', data)\n",
    "    ## Replace mulitple spaces with single space\n",
    "    data = re.sub(' +', ' ', data)\n",
    "    ## Replace blank lines\n",
    "    data = re.sub(r'\\n+', '\\n', data)\n",
    "    ## tokenize sentences\n",
    "    sent_tokens = sent_tokenize(data)\n",
    "    ## Remove full-stop(end of sentence)\n",
    "    data = re.sub(r'[^A-Za-z\\n ]+', ' ', data)\n",
    "    ## Remove stopwords\n",
    "    filtered_text_list = remove_stop_words(data)\n",
    "    ## Get positive_score\n",
    "    pos_score = get_positive_score(filtered_text_list)\n",
    "    ## Get negative score\n",
    "    neg_score = get_negative_score(filtered_text_list)\n",
    "    ## Get polarity score\n",
    "    pol_score = get_polarity_score(pos_score, neg_score)\n",
    "    ## Get average sentences length\n",
    "    avg_sent_length = get_avg_sentence_length(sent_tokens,filtered_text_list)\n",
    "    ## Get percentage of complex words\n",
    "    complex_word_count,perc_complex_words = get_perc_complex_words(filtered_text_list)\n",
    "    ## Get fog index\n",
    "    fog_index = get_fog_index(avg_sent_length,perc_complex_words)\n",
    "    ## Calculate word count\n",
    "    word_count = len(filtered_text_list)\n",
    "    ## Calculate uncertainity score\n",
    "    uncertainity_score = get_uncertainity_score(filtered_text_list)\n",
    "    ## Calculate constrain score\n",
    "    constrain_score = get_constrain_score(filtered_text_list)\n",
    "    ## Calculate Positive word proportion\n",
    "    pos_word_proportion = pos_score/word_count\n",
    "    ## Calculate Negative word proportion\n",
    "    neg_word_proportion = neg_score/word_count\n",
    "    ## Calculate uncertainity word proportion\n",
    "    uncertain_word_proportion = uncertainity_score/word_count\n",
    "    ## Calculate constraint proportion\n",
    "    constraint_proportion = constrain_score/word_count\n",
    "    \n",
    "    result = (pos_score,neg_score,pol_score,avg_sent_length,\n",
    "              perc_complex_words,fog_index,complex_word_count,\n",
    "              word_count,uncertainity_score,constrain_score,\n",
    "              pos_word_proportion,neg_word_proportion,neg_word_proportion,\n",
    "              constraint_proportion)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write_path = './input_dir/new/'+encode_name(secfname)\n",
    "with open(write_path,'w', encoding=\"utf-8\") as w_file:\n",
    "    w_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_whole_report_constraint_index(df):\n",
    "    global_constraint_index = global_constrain_count/(1.0*global_word_count)\n",
    "    df['constraint_index_for_whole_rep'] = global_constraint_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-25</td>\n",
       "      <td>10-Q/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002278.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199812</td>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002401.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199812</td>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002402.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199903</td>\n",
       "      <td>1999-03-31</td>\n",
       "      <td>NT 10-K</td>\n",
       "      <td>edgar/data/3662/0000950172-99-000362.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199905</td>\n",
       "      <td>1999-05-11</td>\n",
       "      <td>10-K</td>\n",
       "      <td>edgar/data/3662/0000950170-99-000775.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811 1998-11-12   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811 1998-11-16  NT 10-Q   \n",
       "5  3662  SUNBEAM CORP/FL/  199811 1998-11-25   10-Q/A   \n",
       "6  3662  SUNBEAM CORP/FL/  199812 1998-12-22     10-Q   \n",
       "7  3662  SUNBEAM CORP/FL/  199812 1998-12-22     10-Q   \n",
       "8  3662  SUNBEAM CORP/FL/  199903 1999-03-31  NT 10-K   \n",
       "9  3662  SUNBEAM CORP/FL/  199905 1999-05-11     10-K   \n",
       "\n",
       "                                   SECFNAME  \n",
       "0  edgar/data/3662/0000950170-98-000413.txt  \n",
       "1  edgar/data/3662/0000950170-98-001001.txt  \n",
       "2  edgar/data/3662/0000950172-98-000783.txt  \n",
       "3  edgar/data/3662/0000950170-98-002145.txt  \n",
       "4  edgar/data/3662/0000950172-98-001203.txt  \n",
       "5  edgar/data/3662/0000950170-98-002278.txt  \n",
       "6  edgar/data/3662/0000950170-98-002401.txt  \n",
       "7  edgar/data/3662/0000950170-98-002402.txt  \n",
       "8  edgar/data/3662/0000950172-99-000362.txt  \n",
       "9  edgar/data/3662/0000950170-99-000775.txt  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for index, row in df.head(10).iterrows():\n",
    "    secfname = row['SECFNAME']\n",
    "    result = preprocess(secfname)\n",
    "    new_list.append(result)\n",
    "\n",
    "columns = ['pos_score','neg_score','pol_score','avg_sent_length',\n",
    "              'perc_complex_words','fog_index','complex_word_count',\n",
    "              'word_count','uncertainity_score','constrain_score',\n",
    "              'pos_word_proportion','neg_word_proportion','neg_word_proportion',\n",
    "              'constraint_proportion']\n",
    "res_df = pd.DataFrame(new_list,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>pol_score</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>perc_complex_words</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>uncertainity_score</th>\n",
       "      <th>constrain_score</th>\n",
       "      <th>pos_word_proportion</th>\n",
       "      <th>neg_word_proportion</th>\n",
       "      <th>neg_word_proportion</th>\n",
       "      <th>constraint_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>614</td>\n",
       "      <td>3452</td>\n",
       "      <td>-0.697983</td>\n",
       "      <td>15.976875</td>\n",
       "      <td>71.027033</td>\n",
       "      <td>34.801563</td>\n",
       "      <td>66737</td>\n",
       "      <td>93960</td>\n",
       "      <td>940</td>\n",
       "      <td>1487</td>\n",
       "      <td>0.006535</td>\n",
       "      <td>0.036739</td>\n",
       "      <td>0.036739</td>\n",
       "      <td>0.015826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>341</td>\n",
       "      <td>1723</td>\n",
       "      <td>-0.669574</td>\n",
       "      <td>15.848524</td>\n",
       "      <td>69.230769</td>\n",
       "      <td>34.031717</td>\n",
       "      <td>42012</td>\n",
       "      <td>60684</td>\n",
       "      <td>859</td>\n",
       "      <td>1046</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>0.028393</td>\n",
       "      <td>0.028393</td>\n",
       "      <td>0.017237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>33.722222</td>\n",
       "      <td>57.990115</td>\n",
       "      <td>36.684935</td>\n",
       "      <td>352</td>\n",
       "      <td>607</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.011532</td>\n",
       "      <td>0.011532</td>\n",
       "      <td>0.008237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>233</td>\n",
       "      <td>1579</td>\n",
       "      <td>-0.742826</td>\n",
       "      <td>12.809294</td>\n",
       "      <td>69.978402</td>\n",
       "      <td>33.115078</td>\n",
       "      <td>33372</td>\n",
       "      <td>47689</td>\n",
       "      <td>553</td>\n",
       "      <td>716</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>0.033110</td>\n",
       "      <td>0.033110</td>\n",
       "      <td>0.015014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>34.952381</td>\n",
       "      <td>58.174387</td>\n",
       "      <td>37.250707</td>\n",
       "      <td>427</td>\n",
       "      <td>734</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.005450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811</td>\n",
       "      <td>1998-11-25</td>\n",
       "      <td>10-Q/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002278.txt</td>\n",
       "      <td>40</td>\n",
       "      <td>426</td>\n",
       "      <td>-0.828326</td>\n",
       "      <td>14.535937</td>\n",
       "      <td>70.568634</td>\n",
       "      <td>34.041829</td>\n",
       "      <td>6565</td>\n",
       "      <td>9303</td>\n",
       "      <td>179</td>\n",
       "      <td>91</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.045792</td>\n",
       "      <td>0.045792</td>\n",
       "      <td>0.009782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199812</td>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002401.txt</td>\n",
       "      <td>97</td>\n",
       "      <td>622</td>\n",
       "      <td>-0.730181</td>\n",
       "      <td>14.467221</td>\n",
       "      <td>69.051570</td>\n",
       "      <td>33.407516</td>\n",
       "      <td>10819</td>\n",
       "      <td>15668</td>\n",
       "      <td>279</td>\n",
       "      <td>271</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.039699</td>\n",
       "      <td>0.039699</td>\n",
       "      <td>0.017296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199812</td>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002402.txt</td>\n",
       "      <td>51</td>\n",
       "      <td>378</td>\n",
       "      <td>-0.762238</td>\n",
       "      <td>13.457182</td>\n",
       "      <td>70.922714</td>\n",
       "      <td>33.751958</td>\n",
       "      <td>6910</td>\n",
       "      <td>9743</td>\n",
       "      <td>201</td>\n",
       "      <td>105</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>0.038797</td>\n",
       "      <td>0.038797</td>\n",
       "      <td>0.010777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199903</td>\n",
       "      <td>1999-03-31</td>\n",
       "      <td>NT 10-K</td>\n",
       "      <td>edgar/data/3662/0000950172-99-000362.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>33.800000</td>\n",
       "      <td>58.284024</td>\n",
       "      <td>36.833609</td>\n",
       "      <td>394</td>\n",
       "      <td>676</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.004438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3662</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199905</td>\n",
       "      <td>1999-05-11</td>\n",
       "      <td>10-K</td>\n",
       "      <td>edgar/data/3662/0000950170-99-000775.txt</td>\n",
       "      <td>278</td>\n",
       "      <td>1779</td>\n",
       "      <td>-0.729703</td>\n",
       "      <td>12.771968</td>\n",
       "      <td>72.214250</td>\n",
       "      <td>33.994487</td>\n",
       "      <td>34218</td>\n",
       "      <td>47384</td>\n",
       "      <td>668</td>\n",
       "      <td>501</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.037544</td>\n",
       "      <td>0.037544</td>\n",
       "      <td>0.010573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIK            CONAME   FYRMO      FDATE     FORM  \\\n",
       "0  3662  SUNBEAM CORP/FL/  199803 1998-03-06  10-K405   \n",
       "1  3662  SUNBEAM CORP/FL/  199805 1998-05-15     10-Q   \n",
       "2  3662  SUNBEAM CORP/FL/  199808 1998-08-13  NT 10-Q   \n",
       "3  3662  SUNBEAM CORP/FL/  199811 1998-11-12   10-K/A   \n",
       "4  3662  SUNBEAM CORP/FL/  199811 1998-11-16  NT 10-Q   \n",
       "5  3662  SUNBEAM CORP/FL/  199811 1998-11-25   10-Q/A   \n",
       "6  3662  SUNBEAM CORP/FL/  199812 1998-12-22     10-Q   \n",
       "7  3662  SUNBEAM CORP/FL/  199812 1998-12-22     10-Q   \n",
       "8  3662  SUNBEAM CORP/FL/  199903 1999-03-31  NT 10-K   \n",
       "9  3662  SUNBEAM CORP/FL/  199905 1999-05-11     10-K   \n",
       "\n",
       "                                   SECFNAME  pos_score  neg_score  pol_score  \\\n",
       "0  edgar/data/3662/0000950170-98-000413.txt        614       3452  -0.697983   \n",
       "1  edgar/data/3662/0000950170-98-001001.txt        341       1723  -0.669574   \n",
       "2  edgar/data/3662/0000950172-98-000783.txt          3          7  -0.400000   \n",
       "3  edgar/data/3662/0000950170-98-002145.txt        233       1579  -0.742826   \n",
       "4  edgar/data/3662/0000950172-98-001203.txt          4          7  -0.272727   \n",
       "5  edgar/data/3662/0000950170-98-002278.txt         40        426  -0.828326   \n",
       "6  edgar/data/3662/0000950170-98-002401.txt         97        622  -0.730181   \n",
       "7  edgar/data/3662/0000950170-98-002402.txt         51        378  -0.762238   \n",
       "8  edgar/data/3662/0000950172-99-000362.txt          3          5  -0.250000   \n",
       "9  edgar/data/3662/0000950170-99-000775.txt        278       1779  -0.729703   \n",
       "\n",
       "   avg_sent_length  perc_complex_words  fog_index  complex_word_count  \\\n",
       "0        15.976875           71.027033  34.801563               66737   \n",
       "1        15.848524           69.230769  34.031717               42012   \n",
       "2        33.722222           57.990115  36.684935                 352   \n",
       "3        12.809294           69.978402  33.115078               33372   \n",
       "4        34.952381           58.174387  37.250707                 427   \n",
       "5        14.535937           70.568634  34.041829                6565   \n",
       "6        14.467221           69.051570  33.407516               10819   \n",
       "7        13.457182           70.922714  33.751958                6910   \n",
       "8        33.800000           58.284024  36.833609                 394   \n",
       "9        12.771968           72.214250  33.994487               34218   \n",
       "\n",
       "   word_count  uncertainity_score  constrain_score  pos_word_proportion  \\\n",
       "0       93960                 940             1487             0.006535   \n",
       "1       60684                 859             1046             0.005619   \n",
       "2         607                   9                5             0.004942   \n",
       "3       47689                 553              716             0.004886   \n",
       "4         734                  10                4             0.005450   \n",
       "5        9303                 179               91             0.004300   \n",
       "6       15668                 279              271             0.006191   \n",
       "7        9743                 201              105             0.005235   \n",
       "8         676                   8                3             0.004438   \n",
       "9       47384                 668              501             0.005867   \n",
       "\n",
       "   neg_word_proportion  neg_word_proportion  constraint_proportion  \n",
       "0             0.036739             0.036739               0.015826  \n",
       "1             0.028393             0.028393               0.017237  \n",
       "2             0.011532             0.011532               0.008237  \n",
       "3             0.033110             0.033110               0.015014  \n",
       "4             0.009537             0.009537               0.005450  \n",
       "5             0.045792             0.045792               0.009782  \n",
       "6             0.039699             0.039699               0.017296  \n",
       "7             0.038797             0.038797               0.010777  \n",
       "8             0.007396             0.007396               0.004438  \n",
       "9             0.037544             0.037544               0.010573  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat((df.head(10),res_df),axis=1)\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
